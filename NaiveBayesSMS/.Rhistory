sms-raw <- read.csv("sms_spam.csv",stringsAsFactors = FALSE)
str(sms_raw)
sms_raw <- read.csv("sms_spam.csv",stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw$type)
install.packages("tm")
library (tm)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:3])
corpus_clean<- tm_map(sms_corpus,tolower)
corpus_clean<- tm_map(corpus_clean,removeNumbers)
corpus_clean<- tm_map(corpus_clean,removeWords, stopwords())
corpus_clean<- tm_map(corpus_clean,stripWhitespace)
sms_dtm <- DocumentTermMatrix(corpus_clean)
corpus_clean<- tm_map(corpus_clean,PlainTextDocument)
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_raw_train <-sms_raw[1:4169,]
sms_raw_train <-sms_raw[4170:5559,]
sms_dtm_train <-sms_dtm[1:4169,]
sms_dtm_train <-sms_dtm[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169,]
sms_corpus_train <-corpus_clean[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169,]
sms_corpus_train <-corpus_clean[1:4169]
sms_corpus_test <-corpus_clean[4170:5559]
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train,min.freq = 40,random.order = FALSE)
spam <- subset(sms_raw_train,type == "spam")
ham <-subset(sms_raw_train,type == "ham")
wordcloud(sms_corpus_train,max.words=40,scale = c(3,0.5))
wordcloud(ham$text,max.words=40,scale = c(3,0.5))
sms_dict <- Dictionary(findFreqTerms(sms_dtm_train,5))
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
sms_dict <- dictionary(findFreqTerms(sms_dtm_train,5))
install.package("Dictionary")
install.packages("Dictionary")
install.packages("dict")
sms_dict <- findFreqTerms(sms_dtm_train,5)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
convert_counts<- function(x){
x <- ifelse(x>0,1,0)
x < factor(x,levels = c(0,1), labels=c(""No"", ""Yes""))
return (x)
}
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
convert_counts<- function(x){
x <- ifelse(x>0,1,0)
x < factor(x,levels = c(0,1), labels=c(""No"", ""Yes""))
return (x)
}
convert_counts<- function(x){
x <- ifelse(x>0,1,0)
x < factor(x,levels = c(0,1), labels=c("No", "Yes"))
return (x)
}
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
warnings()
convert_counts<- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return (x)
}
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train,sms_raw_train$type)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
str(sms_train)
str(sms_raw_train$type)
str(sms_raw_train
)
sms_raw_train <-sms_raw[1:4169,]
sms_raw_test <-sms_raw[4170:5559,]
sms_dtm_train <-sms_dtm[1:4169,]
sms_dtm_test <-sms_dtm[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169]
sms_corpus_test <-corpus_clean[4170:5559]
sms_dict <- findFreqTerms(sms_dtm_train,5)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred <- predict(sms_classifier,sms_test)
library(gmodels)
CrossTable(sms_test_pred,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type,laplace = 1)
sms_test_pred2 <- predict(sms_classifie2r,sms_test)
CrossTable(sms_test_pred2,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
sms_test_pred2 <- predict(sms_classifier2,sms_test)
CrossTable(sms_test_pred2,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
save(sms_classifier,sms_classifier2,"classifiers.RData")
save(sms_classifier,sms_classifier2,file ="classifiers.RData")
load(file="classifiers.RData")
library (tm)
library(wordcloud)
library(e1071)
library(gmodels)
source("NaiveBayesFunctions.R")
#read in raw data
sms_raw <- read.csv("sms_spam.csv",stringsAsFactors = FALSE)
#str(sms_raw)
# type variable from character vector (spam, ham), to factor
sms_raw$type <- factor(sms_raw$type)
#build a corpus of text documents (in this case each sms message is corpus)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
#print(sms_corpus)
#inspect(sms_corpus[1:3])
corpus_clean <- clean_corpus(sms_corpus)
#now perform tokinization.  This will create sparce matrix. count
#of each word in each document (sms message)
sms_dtm <- DocumentTermMatrix(corpus_clean)
#split data into training and test datasets
#in this case we use 75% for training, 25% for test
#first do raw data fram then document term matrix then corpus
sms_raw_train <-sms_raw[1:4169,]
sms_raw_test <-sms_raw[4170:5559,]
sms_dtm_train <-sms_dtm[1:4169,]
sms_dtm_test <-sms_dtm[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169]
sms_corpus_test <-corpus_clean[4170:5559]
#create a wordcloud to look at the data
wordcloud(sms_corpus_train,min.freq = 40,random.order = FALSE)
#also look at clouds of spam and ham subsets
spam <- subset(sms_raw_train,type == "spam")
ham <-subset(sms_raw_train,type == "ham")
wordcloud(spam$text,max.words=40,scale = c(3,0.5))
wordcloud(ham$text,max.words=40,scale = c(3,0.5))
#reduce size of sparce matrix by removing words that are in less than 5 sms messages
sms_dict <- findFreqTerms(sms_dtm_train,5)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
#Change sparce matrix to be yes/no for word appears instead of count
convert_counts<- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return (x)
}
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
#train the model
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
#test the model
sms_test_pred <- predict(sms_classifier,sms_test)
source("NaiveBayesFunctions.R")
clean_corpus()
library (tm)
library(wordcloud)
library(e1071)
library(gmodels)
#Change sparce matrix to be yes/no for word appears instead of count
clean_corpus<- function(corpus){
#run transformations to clean the corpus
#cleas up to remove stopwords, remove numbers, to lower case.
#also remove extra whitespace created in cleaning
corpus_clean<- tm_map(sms_corpus,tolower)
corpus_clean<- tm_map(corpus_clean,removeNumbers)
corpus_clean<- tm_map(corpus_clean,removeWords, stopwords())
corpus_clean<- tm_map(corpus_clean,stripWhitespace)
#change in tm version 0.6.0 does not automatically convert to required TextDocument
#run following before unning DocumentTermMatrix
corpus_clean<- tm_map(corpus_clean,PlainTextDocument)
return (corpus_clean)
}
#Change sparce matrix to be yes/no for word appears instead of count
convert_counts<- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return (x)
}
#source("NaiveBayesFunctions.R")
#read in raw data
sms_raw <- read.csv("sms_spam.csv",stringsAsFactors = FALSE)
#str(sms_raw)
# type variable from character vector (spam, ham), to factor
sms_raw$type <- factor(sms_raw$type)
#build a corpus of text documents (in this case each sms message is corpus)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
#print(sms_corpus)
#inspect(sms_corpus[1:3])
corpus_clean <- clean_corpus(sms_corpus)
#now perform tokinization.  This will create sparce matrix. count
#of each word in each document (sms message)
sms_dtm <- DocumentTermMatrix(corpus_clean)
#split data into training and test datasets
#in this case we use 75% for training, 25% for test
#first do raw data fram then document term matrix then corpus
sms_raw_train <-sms_raw[1:4169,]
sms_raw_test <-sms_raw[4170:5559,]
sms_dtm_train <-sms_dtm[1:4169,]
sms_dtm_test <-sms_dtm[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169]
sms_corpus_test <-corpus_clean[4170:5559]
#create a wordcloud to look at the data
wordcloud(sms_corpus_train,min.freq = 40,random.order = FALSE)
#also look at clouds of spam and ham subsets
spam <- subset(sms_raw_train,type == "spam")
ham <-subset(sms_raw_train,type == "ham")
wordcloud(spam$text,max.words=40,scale = c(3,0.5))
wordcloud(ham$text,max.words=40,scale = c(3,0.5))
#reduce size of sparce matrix by removing words that are in less than 5 sms messages
sms_dict <- findFreqTerms(sms_dtm_train,5)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
#train the model
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
#test the model
sms_test_pred <- predict(sms_classifier,sms_test)
CrossTable(sms_test_pred,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
#train again with lapcle estimator. if a word appeared in zero spam or ham
#not using laplace causes it to have to big a say
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type,laplace = 1)
sms_test_pred2 <- predict(sms_classifier2,sms_test)
CrossTable(sms_test_pred2,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
save(sms_classifier,sms_classifier2,file ="classifiers.RData")
load(file="classifiers.RData")
?source
help source
library(NaiveBayesUtils)
library (tm)
library(wordcloud)
library(e1071)
library(gmodels)
library(NaiveBayesUtils)
#source("NaiveBayesFunctions.R")
#read in raw data
sms_raw <- read.csv("sms_spam.csv",stringsAsFactors = FALSE)
#str(sms_raw)
# type variable from character vector (spam, ham), to factor
sms_raw$type <- factor(sms_raw$type)
?
#build a corpus of text documents (in this case each sms message is corpus)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
#print(sms_corpus)
#inspect(sms_corpus[1:3])
corpus_clean <- clean_corpus(sms_corpus)
#now perform tokinization.  This will create sparce matrix. count
#of each word in each document (sms message)
sms_dtm <- DocumentTermMatrix(corpus_clean)
#split data into training and test datasets
#in this case we use 75% for training, 25% for test
#first do raw data fram then document term matrix then corpus
sms_raw_train <-sms_raw[1:4169,]
sms_raw_test <-sms_raw[4170:5559,]
sms_dtm_train <-sms_dtm[1:4169,]
sms_dtm_test <-sms_dtm[4170:5559,]
sms_corpus_train <-corpus_clean[1:4169]
sms_corpus_test <-corpus_clean[4170:5559]
#create a wordcloud to look at the data
wordcloud(sms_corpus_train,min.freq = 40,random.order = FALSE)
#also look at clouds of spam and ham subsets
spam <- subset(sms_raw_train,type == "spam")
ham <-subset(sms_raw_train,type == "ham")
wordcloud(spam$text,max.words=40,scale = c(3,0.5))
wordcloud(ham$text,max.words=40,scale = c(3,0.5))
#reduce size of sparce matrix by removing words that are in less than 5 sms messages
sms_dict <- findFreqTerms(sms_dtm_train,5)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(dictionary = sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_test,list(dictionary = sms_dict))
sms_train <-apply(sms_train, MARGIN = 2, convert_counts)
sms_test <-apply(sms_test, MARGIN = 2, convert_counts)
#train the model
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
#test the model
sms_test_pred <- predict(sms_classifier,sms_test)
CrossTable(sms_test_pred,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
#train again with lapcle estimator. if a word appeared in zero spam or ham
#not using laplace causes it to have to big a say
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type,laplace = 1)
sms_test_pred2 <- predict(sms_classifier2,sms_test)
CrossTable(sms_test_pred2,sms_raw_test$type,prop.chisq= FALSE, prop.t = FALSE, dnn=c('predicted','actual'))
save(sms_classifier,sms_classifier2,file ="classifiers.RData")
load(file="classifiers.RData")
